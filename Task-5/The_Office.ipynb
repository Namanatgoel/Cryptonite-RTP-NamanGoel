{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "L1j3amiNG_9y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TEXT_PATH = \"/content/sample_data/office_script_clean.txt\"\n",
        "\n",
        "with open(TEXT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(\"Total characters:\", len(text))\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6Y-Ndy1L2VM",
        "outputId": "6f613f1b-dfd4-4e4b-84db-f08a87b05141"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total characters: 3427466\n",
            "Michael: All right Jim. Your quarterlies look very good. How are things at the library?\n",
            "Jim: Oh, I told you. I couldn't close it. So...\n",
            "Michael: So you've come to the master for guidance? Is this what you're saying, grasshopper?\n",
            "Jim: Actually, you called me in here, but yeah.\n",
            "Michael: All right. Well, let me show you how it's done.\n",
            "Michael:  Yes, I'd like to speak to your office manager, please. Yes, hello. This is Michael Scott. I am the Regional Manager of Dunder Mifflin Paper Products. Just w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "\n",
        "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx2char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "print(\"Vocab size:\", vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwhNOkeWL9Sx",
        "outputId": "dae5e25f-3fe0-43d8-e5d5-64333354c589"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = np.array([char2idx[ch] for ch in text], dtype=np.int64)"
      ],
      "metadata": {
        "id": "GUKoXOIuMAtU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_ratio = 0.9\n",
        "split_idx = int(len(encoded) * split_ratio)\n",
        "\n",
        "train_data = encoded[:split_idx]\n",
        "val_data   = encoded[split_idx:]\n",
        "\n",
        "print(len(train_data), len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxpW36qkMKRY",
        "outputId": "d5c1cb56-db34-49f8-d068-364cdfaa0f21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3084719 342747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.seq_len\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.data[idx:idx + self.seq_len]\n",
        "        y = self.data[idx + 1:idx + self.seq_len + 1]\n",
        "\n",
        "        return (\n",
        "            torch.tensor(x, dtype=torch.long),\n",
        "            torch.tensor(y, dtype=torch.long)\n",
        "        )"
      ],
      "metadata": {
        "id": "EQ-6LhaLMZ1W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "train_ds = CharDataset(train_data, SEQ_LEN)\n",
        "val_ds   = CharDataset(val_data, SEQ_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "4EEsALwnMeij"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim=128, hidden_dim=512, num_layers=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            embed_dim,\n",
        "            hidden_dim,\n",
        "            num_layers,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, hidden=None):\n",
        "        x = self.embedding(x)\n",
        "        out, hidden = self.lstm(x, hidden)\n",
        "        logits = self.fc(out)\n",
        "        return logits, hidden"
      ],
      "metadata": {
        "id": "iCPWZgBAMhYk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = CharLSTM(vocab_size).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)"
      ],
      "metadata": {
        "id": "HsgdR95eMmMo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, loader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        logits, _ = model(x)\n",
        "        loss = criterion(\n",
        "            logits.reshape(-1, vocab_size),\n",
        "            y.reshape(-1)\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "def eval_epoch(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits, _ = model(x)\n",
        "            loss = criterion(\n",
        "                logits.reshape(-1, vocab_size),\n",
        "                y.reshape(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(loader)"
      ],
      "metadata": {
        "id": "iWyleYDeMofo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train_epoch(model, train_loader)\n",
        "    val_loss   = eval_epoch(model, val_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch+1:02d} | \"\n",
        "        f\"Train Loss: {train_loss:.4f} | \"\n",
        "        f\"Val Loss: {val_loss:.4f} | \"\n",
        "        f\"Val Perplexity: {np.exp(val_loss):.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "c7Q9ImvdNP9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db832aa9-e065-4447-db37-afb993bb96d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Train Loss: 1.3996 | Val Loss: 1.5184 | Val Perplexity: 4.56\n",
            "Epoch 02 | Train Loss: 1.3505 | Val Loss: 1.4835 | Val Perplexity: 4.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(train_losses, label=\"Train Loss\")\n",
        "plt.plot(val_losses, label=\"Val Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.exp(val_losses), label=\"Validation Perplexity\")\n",
        "plt.legend()\n",
        "plt.title(\"Validation Perplexity\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9u94-kpVOBdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_text, length=500, temperature=0.8):\n",
        "    model.eval()\n",
        "\n",
        "    input_idxs = torch.tensor(\n",
        "        [char2idx[c] for c in start_text],\n",
        "        dtype=torch.long\n",
        "    ).unsqueeze(0).to(device)\n",
        "\n",
        "    generated = start_text\n",
        "    hidden = None\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(length):\n",
        "            logits, hidden = model(input_idxs, hidden)\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "\n",
        "            next_idx = torch.multinomial(probs, 1).item()\n",
        "            generated += idx2char[next_idx]\n",
        "\n",
        "            input_idxs = torch.tensor([[next_idx]], dtype=torch.long).to(device)\n",
        "\n",
        "    return generated"
      ],
      "metadata": {
        "id": "bf3Q2ycUOGWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for T in [0.4, 0.7, 1.0]:\n",
        "    print(f\"\\n--- Temperature {T} ---\\n\")\n",
        "    print(generate_text(model, \"Michael:\", 400, temperature=T))"
      ],
      "metadata": {
        "id": "AbQAtroXryMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4clz0BWMr2Wv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}