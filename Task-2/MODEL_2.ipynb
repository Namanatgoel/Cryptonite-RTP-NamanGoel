{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27230b1-a945-4b85-a7e2-9ed1d8c9c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (6362620, 11)\n",
      "   step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig  \\\n",
      "0     1   PAYMENT   9839.64  C1231006815       170136.0       160296.36   \n",
      "1     1   PAYMENT   1864.28  C1666544295        21249.0        19384.72   \n",
      "2     1  TRANSFER    181.00  C1305486145          181.0            0.00   \n",
      "3     1  CASH_OUT    181.00   C840083671          181.0            0.00   \n",
      "4     1   PAYMENT  11668.14  C2048537720        41554.0        29885.86   \n",
      "\n",
      "      nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud  \n",
      "0  M1979787155             0.0             0.0        0               0  \n",
      "1  M2044282225             0.0             0.0        0               0  \n",
      "2   C553264065             0.0             0.0        1               0  \n",
      "3    C38997010         21182.0             0.0        1               0  \n",
      "4  M1230701703             0.0             0.0        0               0  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['fraud_reported'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 2. Preprocessing\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# ----------------------\u001b[39;00m\n\u001b[32m     21\u001b[39m target = \u001b[33m\"\u001b[39m\u001b[33mfraud_reported\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m X = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m y = df[target].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x==\u001b[33m'\u001b[39m\u001b[33mY\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m).values  \u001b[38;5;66;03m# convert to 0/1\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Convert categorical features to integers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5588\u001b[39m, in \u001b[36mDataFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   5440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdrop\u001b[39m(\n\u001b[32m   5441\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   5442\u001b[39m     labels: IndexLabel | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5449\u001b[39m     errors: IgnoreRaise = \u001b[33m\"\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   5450\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5451\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   5452\u001b[39m \u001b[33;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[32m   5453\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   5586\u001b[39m \u001b[33;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[32m   5587\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m5588\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5589\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5590\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5591\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5592\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5593\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5594\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5595\u001b[39m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5596\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4807\u001b[39m, in \u001b[36mNDFrame.drop\u001b[39m\u001b[34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[39m\n\u001b[32m   4805\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes.items():\n\u001b[32m   4806\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4807\u001b[39m         obj = \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4809\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[32m   4810\u001b[39m     \u001b[38;5;28mself\u001b[39m._update_inplace(obj)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:4849\u001b[39m, in \u001b[36mNDFrame._drop_axis\u001b[39m\u001b[34m(self, labels, axis, level, errors, only_slice)\u001b[39m\n\u001b[32m   4847\u001b[39m         new_axis = axis.drop(labels, level=level, errors=errors)\n\u001b[32m   4848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4849\u001b[39m         new_axis = \u001b[43maxis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4850\u001b[39m     indexer = axis.get_indexer(new_axis)\n\u001b[32m   4852\u001b[39m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[32m   4853\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7136\u001b[39m, in \u001b[36mIndex.drop\u001b[39m\u001b[34m(self, labels, errors)\u001b[39m\n\u001b[32m   7134\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mask.any():\n\u001b[32m   7135\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors != \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7136\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask].tolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not found in axis\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   7137\u001b[39m     indexer = indexer[~mask]\n\u001b[32m   7138\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.delete(indexer)\n",
      "\u001b[31mKeyError\u001b[39m: \"['fraud_reported'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Online Payment Fraud Detection\n",
    "# Decision Tree and Random Forest from scratch (No sklearn)\n",
    "# ------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "# ----------------------\n",
    "# 1. Load dataset\n",
    "# ----------------------\n",
    "df = pd.read_csv(\"onlinefraud.csv\")  # put CSV in working directory\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "# ----------------------\n",
    "# 2. Preprocessing\n",
    "# ----------------------\n",
    "target = \"fraud_reported\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target].apply(lambda x: 1 if x=='Y' else 0).values  # convert to 0/1\n",
    "\n",
    "# Convert categorical features to integers\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col] = pd.factorize(X[col])[0]\n",
    "\n",
    "# Fill missing numeric values with median\n",
    "X = X.fillna(X.median())\n",
    "X = X.values\n",
    "\n",
    "# ----------------------\n",
    "# 3. Train/Test split (from scratch)\n",
    "# ----------------------\n",
    "def train_test_split_custom(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(len(X)*(1-test_size))\n",
    "    train_idx = indices[:split]\n",
    "    test_idx = indices[split:]\n",
    "    return X[train_idx], X[test_idx], y[train_idx], y[test_idx]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split_custom(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ----------------------\n",
    "# 4. Decision Tree (ID3)\n",
    "# ----------------------\n",
    "def entropy(y):\n",
    "    counts = np.bincount(y)\n",
    "    probs = counts / len(y)\n",
    "    return -np.sum([p*np.log2(p) for p in probs if p>0])\n",
    "\n",
    "def information_gain(y, y_left, y_right):\n",
    "    return entropy(y) - (len(y_left)/len(y)*entropy(y_left) + len(y_right)/len(y)*entropy(y_right))\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, predicted_class=None):\n",
    "        self.feature_idx = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.predicted_class = predicted_class\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.root = self._grow_tree(X, y)\n",
    "    \n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y==i) for i in np.unique(y)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(predicted_class=predicted_class)\n",
    "        \n",
    "        if depth < self.max_depth and len(y) >= self.min_samples_split:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] <= thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_idx = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth+1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth+1)\n",
    "        return node\n",
    "    \n",
    "    def _best_split(self, X, y):\n",
    "        best_gain = -1\n",
    "        split_idx, split_thr = None, None\n",
    "        for idx in range(X.shape[1]):\n",
    "            thresholds = np.unique(X[:, idx])\n",
    "            for thr in thresholds:\n",
    "                y_left = y[X[:, idx] <= thr]\n",
    "                y_right = y[X[:, idx] > thr]\n",
    "                if len(y_left)==0 or len(y_right)==0:\n",
    "                    continue\n",
    "                gain = information_gain(y, y_left, y_right)\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    split_idx = idx\n",
    "                    split_thr = thr\n",
    "        return split_idx, split_thr\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_inputs(inputs) for inputs in X])\n",
    "    \n",
    "    def _predict_inputs(self, inputs):\n",
    "        node = self.root\n",
    "        while node.left:\n",
    "            if inputs[node.feature_idx] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class\n",
    "\n",
    "# ----------------------\n",
    "# 5. Random Forest from scratch\n",
    "# ----------------------\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=5, max_depth=5, min_samples_split=2, max_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "        self.max_features = max_features  # number of features to sample per tree\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            # Bootstrap sample\n",
    "            indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            X_sample = X[indices]\n",
    "            y_sample = y[indices]\n",
    "            # Feature subsample\n",
    "            if self.max_features is None:\n",
    "                max_feat = X.shape[1]\n",
    "            else:\n",
    "                max_feat = self.max_features\n",
    "            feat_indices = np.random.choice(X.shape[1], max_feat, replace=False)\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X_sample[:, feat_indices], y_sample)\n",
    "            tree.feat_indices = feat_indices  # store feature indices used\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Majority vote\n",
    "        tree_preds = np.array([tree.predict(X[:, tree.feat_indices]) for tree in self.trees])\n",
    "        return np.array([Counter(tree_preds[:,i]).most_common(1)[0][0] for i in range(X.shape[0])])\n",
    "\n",
    "# ----------------------\n",
    "# 6. Metrics (from scratch)\n",
    "# ----------------------\n",
    "def confusion_matrix_custom(y_true, y_pred):\n",
    "    TP = np.sum((y_true==1) & (y_pred==1))\n",
    "    TN = np.sum((y_true==0) & (y_pred==0))\n",
    "    FP = np.sum((y_true==0) & (y_pred==1))\n",
    "    FN = np.sum((y_true==1) & (y_pred==0))\n",
    "    return np.array([[TP, FP],[FN, TN]])\n",
    "\n",
    "def precision_score_custom(y_true, y_pred):\n",
    "    TP = np.sum((y_true==1) & (y_pred==1))\n",
    "    FP = np.sum((y_true==0) & (y_pred==1))\n",
    "    return TP / (TP + FP + 1e-8)\n",
    "\n",
    "def recall_score_custom(y_true, y_pred):\n",
    "    TP = np.sum((y_true==1) & (y_pred==1))\n",
    "    FN = np.sum((y_true==1) & (y_pred==0))\n",
    "    return TP / (TP + FN + 1e-8)\n",
    "\n",
    "def f1_score_custom(y_true, y_pred):\n",
    "    p = precision_score_custom(y_true, y_pred)\n",
    "    r = recall_score_custom(y_true, y_pred)\n",
    "    return 2*p*r / (p+r+1e-8)\n",
    "\n",
    "# Optional: simple AUC using ranks\n",
    "def auc_score_custom(y_true, y_score):\n",
    "    pos = y_score[y_true==1]\n",
    "    neg = y_score[y_true==0]\n",
    "    n_pos = len(pos)\n",
    "    n_neg = len(neg)\n",
    "    count = 0\n",
    "    for p in pos:\n",
    "        count += np.sum(p > neg)\n",
    "        count += 0.5*np.sum(p == neg)\n",
    "    return count / (n_pos * n_neg + 1e-8)\n",
    "\n",
    "# ----------------------\n",
    "# 7. Train Random Forest\n",
    "# ----------------------\n",
    "rf = RandomForest(n_trees=5, max_depth=5, min_samples_split=5, max_features=int(np.sqrt(X_train.shape[1])))\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix_custom(y_test, y_pred)\n",
    "precision = precision_score_custom(y_test, y_pred)\n",
    "recall = recall_score_custom(y_test, y_pred)\n",
    "f1 = f1_score_custom(y_test, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1-score: {f1:.2f}\")\n",
    "\n",
    "# ----------------------\n",
    "# 8. Feature importance (basic)\n",
    "# Count how many times each feature is used across all trees\n",
    "# ----------------------\n",
    "feature_count = np.zeros(X_train.shape[1])\n",
    "for tree in rf.trees:\n",
    "    def traverse(node):\n",
    "        if node.left:\n",
    "            feature_count[node.feature_idx] += 1\n",
    "            traverse(node.left)\n",
    "            traverse(node.right)\n",
    "    traverse(tree.root)\n",
    "\n",
    "for i, col in enumerate(df.drop(columns=[target]).columns):\n",
    "    print(f\"{col}: {feature_count[i]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afb749b-c22b-44c8-9cfe-e08a68960d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
