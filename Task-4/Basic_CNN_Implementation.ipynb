{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81debc87",
   "metadata": {},
   "source": [
    "Basic CNN Implementation on Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef75ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b4b7b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert images to tensors and normalize pixel values\n",
    "# Fashion-MNIST images are grayscale (1 channel)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                     # [0,255] -> [0,1]\n",
    "    transforms.Normalize((0.5,), (0.5,))       # normalize [0,1] -> [-1,1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29956b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "full_train_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(\n",
    "    root=\"data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_size = int(0.9 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_train_dataset, [train_size, val_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9750e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_layers():\n",
    "    layers = {\n",
    "        \"conv1\": nn.Conv2d(1, 32, 3, padding=1),\n",
    "        \"conv2\": nn.Conv2d(32, 64, 3, padding=1),\n",
    "        \"conv3\": nn.Conv2d(64, 128, 3, padding=1),\n",
    "        \"fc1\": nn.Linear(128 * 3 * 3, 256),\n",
    "        \"fc2\": nn.Linear(256, 10),\n",
    "        \"pool\": nn.MaxPool2d(2, 2)\n",
    "    }\n",
    "    return layers\n",
    "\n",
    "def forward_pass(x, layers):\n",
    "    x = layers[\"pool\"](F.relu(layers[\"conv1\"](x)))\n",
    "    x = layers[\"pool\"](F.relu(layers[\"conv2\"](x)))\n",
    "    x = layers[\"pool\"](F.relu(layers[\"conv3\"](x)))\n",
    "\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.relu(layers[\"fc1\"](x))\n",
    "    logits = layers[\"fc2\"](x)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "480efbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(layers, loader, optimizer, loss_fn):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        logits = forward_pass(images, layers)\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac713e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(layers, loader):\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            logits = forward_pass(images, layers)\n",
    "            predictions = logits.argmax(dim=1)\n",
    "\n",
    "            y_true.extend(labels.numpy())\n",
    "            y_pred.extend(predictions.numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\"\n",
    "    )\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return acc, p, r, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d22a8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss: 0.5314 | Val Acc: 0.8748 | Val F1: 0.8774\n",
      "Epoch 2/15 | Train Loss: 0.3051 | Val Acc: 0.8968 | Val F1: 0.8957\n",
      "Epoch 3/15 | Train Loss: 0.2559 | Val Acc: 0.9017 | Val F1: 0.9013\n",
      "Epoch 4/15 | Train Loss: 0.2277 | Val Acc: 0.9130 | Val F1: 0.9125\n",
      "Epoch 5/15 | Train Loss: 0.2027 | Val Acc: 0.9122 | Val F1: 0.9119\n",
      "Epoch 6/15 | Train Loss: 0.1795 | Val Acc: 0.9223 | Val F1: 0.9223\n",
      "Epoch 7/15 | Train Loss: 0.1608 | Val Acc: 0.9163 | Val F1: 0.9166\n",
      "Epoch 8/15 | Train Loss: 0.1466 | Val Acc: 0.9195 | Val F1: 0.9194\n",
      "Epoch 9/15 | Train Loss: 0.1292 | Val Acc: 0.9152 | Val F1: 0.9150\n",
      "Epoch 10/15 | Train Loss: 0.1164 | Val Acc: 0.9198 | Val F1: 0.9203\n",
      "Epoch 11/15 | Train Loss: 0.1012 | Val Acc: 0.9247 | Val F1: 0.9244\n",
      "Epoch 12/15 | Train Loss: 0.0873 | Val Acc: 0.9242 | Val F1: 0.9231\n",
      "Epoch 13/15 | Train Loss: 0.0755 | Val Acc: 0.9233 | Val F1: 0.9220\n",
      "Epoch 14/15 | Train Loss: 0.0662 | Val Acc: 0.9237 | Val F1: 0.9221\n",
      "Epoch 15/15 | Train Loss: 0.0588 | Val Acc: 0.9187 | Val F1: 0.9193\n",
      "\n",
      "Test Results:\n",
      "Accuracy : 0.9094\n",
      "Precision: 0.9146723141328431\n",
      "Recall   : 0.9094\n",
      "F1-score : 0.9104491418045975\n",
      "Confusion Matrix:\n",
      " [[760   1  28  10   4   1 187   0   9   0]\n",
      " [  3 986   0   6   1   0   3   0   1   0]\n",
      " [  4   0 872   7  55   0  61   0   1   0]\n",
      " [ 12   3  11 883  37   1  50   0   3   0]\n",
      " [  0   1  33  13 879   0  74   0   0   0]\n",
      " [  0   0   0   0   0 980   0  14   0   6]\n",
      " [ 39   2  62  12  64   0 818   0   3   0]\n",
      " [  0   0   0   0   0  11   0 968   0  21]\n",
      " [  1   0   3   2   1   1   0   2 990   0]\n",
      " [  0   0   0   0   0   5   1  36   0 958]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    layers = create_cnn_layers()\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [p for layer in layers.values() for p in layer.parameters()],\n",
    "        lr=1e-3\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    epochs = 15\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = train_one_epoch(\n",
    "            layers, train_loader, optimizer, loss_fn\n",
    "        )\n",
    "\n",
    "        val_acc, val_p, val_r, val_f1, _ = evaluate_model(\n",
    "            layers, val_loader\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{epochs} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | \"\n",
    "            f\"Val Acc: {val_acc:.4f} | \"\n",
    "            f\"Val F1: {val_f1:.4f}\"\n",
    "        )\n",
    "\n",
    "    test_acc, test_p, test_r, test_f1, test_cm = evaluate_model(\n",
    "        layers, test_loader\n",
    "    )\n",
    "\n",
    "    print(\"\\nTest Results:\")\n",
    "    print(\"Accuracy :\", test_acc)\n",
    "    print(\"Precision:\", test_p)\n",
    "    print(\"Recall   :\", test_r)\n",
    "    print(\"F1-score :\", test_f1)\n",
    "    print(\"Confusion Matrix:\\n\", test_cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899f155",
   "metadata": {},
   "source": [
    "Methods  \n",
    "A custom convolutional neural network with three convolutional layers was implemented from scratch using PyTorch for Fashion-MNIST image classification. The dataset was split into training, validation, and test sets. The model was trained using the Adam optimizer and cross-entropy loss. Performance was evaluated using accuracy, precision, recall, F1-score, and a confusion matrix.  \n",
    "  \n",
    "Results    \n",
    "Macro averaging computes precision, recall, and F1-score independently for each class and then averages them equally across classes. This approach ensures that performance on all classes contributes equally to the final metric, preventing dominant or easy classes from masking poor performance on harder classes. For Fashion-MNIST, where class frequencies are balanced but visual difficulty varies, macro-averaged metrics provide a fair and informative evaluation of model performance.  \n",
    "  \n",
    "The CNN achieved a test accuracy of 90.9% and a macro-averaged F1-score of 0.91. Strong performance was observed across most classes, with confusion primarily occurring between visually similar clothing categories such as T-shirts, pullovers, and shirts. Validation performance peaked around epoch 11â€“12, indicating optimal convergence without significant overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptonite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
