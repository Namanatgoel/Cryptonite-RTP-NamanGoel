{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf7eb5d",
   "metadata": {},
   "source": [
    "DeepWeeds Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5254b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c564769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT = \"Deepweeds\"\n",
    "IMAGE_DIR = os.path.join(DATA_ROOT, \"images\")\n",
    "LABEL_DIR = os.path.join(DATA_ROOT, \"labels\")\n",
    "\n",
    "# Sanity checks\n",
    "assert os.path.exists(IMAGE_DIR), f\"Images directory not found: {IMAGE_DIR}\"\n",
    "assert os.path.exists(LABEL_DIR), f\"Labels directory not found: {LABEL_DIR}\"\n",
    "\n",
    "FOLD = 0                  # choose 0–4 as per the files\n",
    "FULL_FINETUNE = False     # False = partial, True = full\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "LR_PARTIAL = 1e-3\n",
    "LR_FULL = 1e-4\n",
    "NUM_CLASSES = 9\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd075607",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "57764e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CSVs:\n",
      "Deepweeds/labels/train_subset0.csv\n",
      "Deepweeds/labels/val_subset0.csv\n",
      "Deepweeds/labels/test_subset0.csv\n"
     ]
    }
   ],
   "source": [
    "train_csv = os.path.join(LABEL_DIR, f\"train_subset{FOLD}.csv\")\n",
    "val_csv   = os.path.join(LABEL_DIR, f\"val_subset{FOLD}.csv\")\n",
    "test_csv  = os.path.join(LABEL_DIR, f\"test_subset{FOLD}.csv\")\n",
    "\n",
    "assert os.path.exists(train_csv), \"Train CSV not found\"\n",
    "assert os.path.exists(val_csv), \"Validation CSV not found\"\n",
    "assert os.path.exists(test_csv), \"Test CSV not found\"\n",
    "\n",
    "print(\"Using CSVs:\")\n",
    "print(train_csv)\n",
    "print(val_csv)\n",
    "print(test_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "225a992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepWeedsDataset(Dataset):\n",
    "    def __init__(self, csv_file, image_dir, transform):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.data.iloc[idx][\"Filename\"]\n",
    "        label = int(self.data.iloc[idx][\"Label\"])\n",
    "\n",
    "        image_path = os.path.join(self.image_dir, filename)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "757e13e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples → Train: 10501 Val: 3501 Test: 3507\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DeepWeedsDataset(train_csv, IMAGE_DIR, train_transform)\n",
    "val_dataset   = DeepWeedsDataset(val_csv, IMAGE_DIR, eval_transform)\n",
    "test_dataset  = DeepWeedsDataset(test_csv, IMAGE_DIR, eval_transform)\n",
    "\n",
    "print(\"Samples → Train:\", len(train_dataset),\n",
    "      \"Val:\", len(val_dataset),\n",
    "      \"Test:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d7e0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "894d1731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "def create_model(num_classes, full_finetune):\n",
    "    weights = ResNet50_Weights.DEFAULT\n",
    "    model = resnet50(weights=weights)\n",
    "\n",
    "    \"\"\" FOR JUST FC TRAINING\n",
    "    if not full_finetune:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False \"\"\"\n",
    "\n",
    "    \"\"\"FOR PARTIAL UNFREEZING (LAST RESNET BLOCK) WITH FC TRAINING (by default)\n",
    "    # Freeze entire backbone first\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze ONLY the last ResNet block (layer4)\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\"\"\"\n",
    "    \n",
    "    # FULL FINE-TUNING: unfreeze everything\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "model = create_model(NUM_CLASSES, FULL_FINETUNE)\n",
    "model = model.to(device)\n",
    "\n",
    "print(\"Model on device:\", next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c4e7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR_FULL if FULL_FINETUNE else LR_PARTIAL\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8789b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "    return total_loss / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97c2c935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            preds = model(images).argmax(dim=1)\n",
    "\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=\"macro\"\n",
    "    )\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    return acc, p, r, f1, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fd17427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 | Train Loss: 1.0034 | Val Acc: 0.8375 | Val F1: 0.7834\n",
      "Epoch 2/15 | Train Loss: 0.5093 | Val Acc: 0.8703 | Val F1: 0.8204\n",
      "Epoch 3/15 | Train Loss: 0.4015 | Val Acc: 0.8883 | Val F1: 0.8564\n",
      "Epoch 4/15 | Train Loss: 0.3388 | Val Acc: 0.8969 | Val F1: 0.8676\n",
      "Epoch 5/15 | Train Loss: 0.2925 | Val Acc: 0.9306 | Val F1: 0.9114\n",
      "Epoch 6/15 | Train Loss: 0.2652 | Val Acc: 0.9289 | Val F1: 0.9113\n",
      "Epoch 7/15 | Train Loss: 0.2432 | Val Acc: 0.9403 | Val F1: 0.9239\n",
      "Epoch 8/15 | Train Loss: 0.2289 | Val Acc: 0.9414 | Val F1: 0.9246\n",
      "Epoch 9/15 | Train Loss: 0.2092 | Val Acc: 0.9360 | Val F1: 0.9184\n",
      "Epoch 10/15 | Train Loss: 0.2006 | Val Acc: 0.9520 | Val F1: 0.9370\n",
      "Epoch 11/15 | Train Loss: 0.1990 | Val Acc: 0.9420 | Val F1: 0.9266\n",
      "Epoch 12/15 | Train Loss: 0.1758 | Val Acc: 0.9363 | Val F1: 0.9129\n",
      "Epoch 13/15 | Train Loss: 0.1696 | Val Acc: 0.9414 | Val F1: 0.9243\n",
      "Epoch 14/15 | Train Loss: 0.1713 | Val Acc: 0.9429 | Val F1: 0.9236\n",
      "Epoch 15/15 | Train Loss: 0.1615 | Val Acc: 0.9429 | Val F1: 0.9258\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, loss_fn)\n",
    "    val_acc, val_p, val_r, val_f1, _ = evaluate(model, val_loader)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{EPOCHS} | \"\n",
    "        f\"Train Loss: {train_loss:.4f} | \"\n",
    "        f\"Val Acc: {val_acc:.4f} | \"\n",
    "        f\"Val F1: {val_f1:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6132e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DeepWeeds Test Results\n",
      "Accuracy : 0.9404049044767607\n",
      "Precision: 0.9391832607900044\n",
      "Recall   : 0.9054789887953478\n",
      "F1-score : 0.9195922945542416\n",
      "Confusion Matrix:\n",
      " [[ 170    0    0    0    0    3    0   20   33]\n",
      " [   0  189    0    0    0    1    5    6   12]\n",
      " [   0    0  205    0    0    0    0    0    2]\n",
      " [   1    0    3  182    5    0    0    0   14]\n",
      " [   0    0   18    0  183    0    0    0   12]\n",
      " [   0    0    0    0    0  187    2    1   12]\n",
      " [   0    0    0    0    0    0  211    0    4]\n",
      " [   2    2    0    1    1    0    2  180   16]\n",
      " [   4    1    5    0    7    2   10    2 1791]]\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_p, test_r, test_f1, test_cm = evaluate(model, test_loader)\n",
    "\n",
    "print(\"\\nDeepWeeds Test Results\")\n",
    "print(\"Accuracy :\", test_acc)\n",
    "print(\"Precision:\", test_p)\n",
    "print(\"Recall   :\", test_r)\n",
    "print(\"F1-score :\", test_f1)\n",
    "print(\"Confusion Matrix:\\n\", test_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f89849a",
   "metadata": {},
   "source": [
    "On training just the classifier head  (ResNet frozen)   \n",
    "(       for param in model.parameters():  \n",
    "            param.requires_grad = False  \n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes))  \n",
    "  \n",
    "lr = 1e-3  \n",
    "  \n",
    "Epoch 1/15 | Train Loss: 1.1900 | Val Acc: 0.6144 | Val F1: 0.3587  \n",
    "Epoch 15/15 | Train Loss: 0.6840 | Val Acc: 0.7586 | Val F1: 0.6683\n",
    "    \n",
    "DeepWeeds Test Results  \n",
    "Accuracy : 0.761619617907043  \n",
    "Precision: 0.832071002990892  \n",
    "Recall   : 0.5947460844495133  \n",
    "F1-score : 0.6778236475786831  \n",
    "Confusion Matrix:  \n",
    " [[ 111    5    0    4    2    3    1    7   93]  \n",
    " [   0  116    0    0    0    2    2    5   88]  \n",
    " [   0    0  142    1    9    0    0    0   55]  \n",
    " [   0    0    2   71    6    4    0    0  122]  \n",
    " [   0    0    3    3  143    1    0    0   63]  \n",
    " [   0    0    0    0    0  129    1    0   72]  \n",
    " [   0    2    0    0    0    2  128    2   81]  \n",
    " [  10    6    0    1    1    6    1   86   93]  \n",
    " [  12    7    2    8   16   22    5    5 1745]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b953d7",
   "metadata": {},
   "source": [
    "On training partially frozen (resnet last block) along with fc layer  \n",
    "lr = 1e-4    \n",
    "  \n",
    "Epoch 1/15 | Train Loss: 1.1141 | Val Acc: 0.7726 | Val F1: 0.6861  \n",
    "Epoch 15/15 | Train Loss: 0.2407 | Val Acc: 0.9206 | Val F1: 0.8976  \n",
    "  \n",
    "DeepWeeds Test Results  \n",
    "Accuracy : 0.9184488166524095  \n",
    "Precision: 0.900410258967554  \n",
    "Recall   : 0.8939264895038266  \n",
    "F1-score : 0.8951552667033433  \n",
    "Confusion Matrix:  \n",
    " [[ 174    4    0    7    0    0    1   19   21]  \n",
    " [   0  199    0    0    0    0    3    4    7]  \n",
    " [   1    0  201    3    2    0    0    0    0]  \n",
    " [   0    0    6  188    5    0    0    0    6]  \n",
    " [   0    0    5    7  192    0    0    0    9]  \n",
    " [   0    0    0    1    1  168    2    2   28]  \n",
    " [   0    0    0    0    0    0  205    0   10]  \n",
    " [   3    3    0    5    0    0    0  167   26]  \n",
    " [   6   15   12   11   13    7   21   10 1727]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672a06db",
   "metadata": {},
   "source": [
    "On training fully resnet model with fc layer  \n",
    "lr = 1e-4  \n",
    "  \n",
    "Epoch 1/15 | Train Loss: 1.0034 | Val Acc: 0.8375 | Val F1: 0.7834  \n",
    "Epoch 15/15 | Train Loss: 0.1615 | Val Acc: 0.9429 | Val F1: 0.9258  \n",
    "  \n",
    "DeepWeeds Test Results  \n",
    "Accuracy : 0.9404049044767607  \n",
    "Precision: 0.9391832607900044  \n",
    "Recall   : 0.9054789887953478  \n",
    "F1-score : 0.9195922945542416  \n",
    "Confusion Matrix:  \n",
    " [[ 170    0    0    0    0    3    0   20   33]  \n",
    " [   0  189    0    0    0    1    5    6   12]  \n",
    " [   0    0  205    0    0    0    0    0    2]  \n",
    " [   1    0    3  182    5    0    0    0   14]  \n",
    " [   0    0   18    0  183    0    0    0   12]  \n",
    " [   0    0    0    0    0  187    2    1   12]  \n",
    " [   0    0    0    0    0    0  211    0    4]  \n",
    " [   2    2    0    1    1    0    2  180   16]  \n",
    " [   4    1    5    0    7    2   10    2 1791]]  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptonite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
